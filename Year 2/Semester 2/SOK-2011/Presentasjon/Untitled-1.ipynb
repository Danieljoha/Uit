{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lim in PostUrl som spørringen skal postes mot\n",
    "postUrl = \"https://trafikkdata-api.atlas.vegvesen.no/\"\n",
    "# Definerer overskriftene for spørringen inkludert innholdstypen Det er rare kommentarer her siden jeg først tenkte å lage en liten tutorial å sende.\n",
    "headers = {\n",
    "    \"content-type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Spørringen og endepunktet til API-et må skrives etter hva du vil hente ut i GraphQL format.\n",
    "apiQuery = \"\"\"\n",
    "{\n",
    "trafficRegistrationPoints(searchQuery: {}) {\n",
    "    id\n",
    "    name\n",
    "    location {\n",
    "    municipality {\n",
    "        name\n",
    "        number\n",
    "        county{\n",
    "        name\n",
    "        }\n",
    "    }\n",
    "    coordinates {\n",
    "        latLon {\n",
    "        lat\n",
    "        lon\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "}\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Konverter spørringen til en JSON-streng\n",
    "payload = json.dumps({\n",
    "    \"query\": apiQuery\n",
    "})\n",
    "\n",
    "# Gjør en POST-forespørsel til API-et med overskriftene og nyttelasten\n",
    "response = requests.post(postUrl, headers=headers, data=payload)\n",
    "\n",
    "# Sjekk om svarstatuskoden er 200 (vellykket)\n",
    "if response.status_code == 200:\n",
    "    # Analyser JSON-dataene i svaret\n",
    "    response_data = response.json()\n",
    "    # vi må unneste dataen slik at vi får det i kolonner\n",
    "    df = pd.json_normalize(response_data['data']['trafficRegistrationPoints'])\n",
    "else:\n",
    "    # Skriv ut en feilmelding hvis statuskoden ikke er 200\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "\n",
    "#location.municipality.name = Tromsø\n",
    "df = df[df['location.municipality.name'] == 'Tromsø']\n",
    "df = df.reset_index(drop=True)\n",
    "#drop location.municipality.number and name and county\n",
    "df = df.drop(['location.municipality.number', 'location.municipality.name', 'location.municipality.county.name'], axis=1)\n",
    "#clean column names from location.coordinates.latLon.lat to lat and location.coordinates.latLon.lon to lon\n",
    "df.columns = df.columns.str.replace('location.coordinates.latLon.lat', 'lat', regex=False) #setter regex to false siden jeg vil bare skifte nøyaktig det navnet\n",
    "df.columns = df.columns.str.replace('location.coordinates.latLon.lon', 'lon', regex=False)\n",
    "\n",
    "\n",
    "\n",
    "# henter trafficRegistrationPointIds fra df\n",
    "traffic_registration_point_ids = df['id'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.69 GiB for an array with shape (3, 388814820) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 91\u001b[0m\n\u001b[0;32m     82\u001b[0m df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(all_rows)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m##\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m#KOMBINERER\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \n\u001b[0;32m     89\u001b[0m \n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m#i merge df og df1\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mny_trafikkdata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:10490\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10471\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m  10472\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m  10473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10486\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10487\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m  10488\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m> 10490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10491\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10500\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:183\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    170\u001b[0m         left_df,\n\u001b[0;32m    171\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:885\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    883\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 885\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:845\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    837\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m _items_overlap_with_suffix(\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuffixes\n\u001b[0;32m    839\u001b[0m )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m--> 845\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m \u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m     left \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(lmgr, axes\u001b[38;5;241m=\u001b[39mlmgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    855\u001b[0m left\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m join_index\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:670\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    663\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    664\u001b[0m         indexer,\n\u001b[0;32m    665\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    666\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    667\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    668\u001b[0m     )\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    681\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    682\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:671\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    663\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    664\u001b[0m         indexer,\n\u001b[0;32m    665\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    666\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    667\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    668\u001b[0m     )\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 671\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    679\u001b[0m     ]\n\u001b[0;32m    681\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    682\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1061\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1061\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:118\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    117\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:158\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    156\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    160\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    161\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.69 GiB for an array with shape (3, 388814820) and data type object"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the start and end datetime objects\n",
    "start_datetime = datetime.datetime(2018, 1, 1, 23, 0, 0)\n",
    "end_datetime = datetime.datetime(2024, 5, 27, 23, 0, 0)\n",
    "\n",
    "# Define the time delta for each iteration\n",
    "time_delta = datetime.timedelta(hours=100)\n",
    "\n",
    "# Initialize the list to store the results\n",
    "all_rows = []\n",
    "\n",
    "# Loop through the time range and send the requests\n",
    "while start_datetime < end_datetime:\n",
    "    # Definerer GraphQL query med \"test\" for hver trafficRegistrationPointId og setter en new line for hver for å lese i request outputtet om det er rett\n",
    "    query = \"\"\"\n",
    "    {\n",
    "    \"\"\" + \"\\n\".join(\n",
    "        f\"\"\"\n",
    "    test_{id.replace(':', '_')}: trafficData(trafficRegistrationPointId: \"{id}\") {{\n",
    "        volume {{\n",
    "        byHour(\n",
    "            from: \"{start_datetime.isoformat()}+02:00\"\n",
    "            to: \"{(start_datetime + time_delta).isoformat()}+02:00\"\n",
    "        ) {{\n",
    "            edges {{\n",
    "            node {{\n",
    "                from\n",
    "                to\n",
    "                byDirection {{\n",
    "                heading\n",
    "                total {{\n",
    "                    volumeNumbers {{\n",
    "                        volume\n",
    "                    }}\n",
    "                    coverage {{\n",
    "                        percentage\n",
    "                        }}\n",
    "                }}\n",
    "                }}\n",
    "            }}\n",
    "            }}\n",
    "        }}\n",
    "        }}\n",
    "    }}\n",
    "        \"\"\"\n",
    "        for id in traffic_registration_point_ids\n",
    "    ) + \"}\"\n",
    "    \n",
    "    # setter inn link og overskrifter og definerer data for query\n",
    "    url = \"https://trafikkdata-api.atlas.vegvesen.no/\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"query\": query}\n",
    "\n",
    "    # Sender requesten og henter resultatet\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    result = response.json()\n",
    "\n",
    "    # henter resultatet fra data som er nestet\n",
    "    data = result['data']\n",
    "\n",
    "    # lager en liste of dictionaries, en for hver trafficregistrationpoint. jeg fjerner alias siden jeg ikke trenger det lengere. setter en \"if\" statement for å fjerne problem om nonetype og legger til 0 istedenfor der det er None\n",
    "    rows = [    \n",
    "        {        \n",
    "            'id': key.replace(\"test_\", \"\"),        \n",
    "            'from': item['node']['from'],\n",
    "            'to': item['node']['to'],\n",
    "            'heading': heading['heading'],\n",
    "            'volume': heading['total']['volumeNumbers']['volume'] if heading['total']['volumeNumbers'] is not None else 0,\n",
    "            'coverage': heading['total']['coverage']['percentage'] if heading['total']['coverage'] is not None else 0\n",
    "        }\n",
    "        for key, value in data.items()\n",
    "        for item in value['volume']['byHour']['edges']\n",
    "        for heading in item['node']['byDirection']\n",
    "    ]\n",
    "    \n",
    "    # Append the rows to the list of all rows\n",
    "    all_rows += rows\n",
    "    \n",
    "    # Increment the start datetime\n",
    "    start_datetime += time_delta\n",
    "\n",
    "# lager et dataframe fra listen av dictionaries\n",
    "df1 = pd.DataFrame.from_dict(all_rows)\n",
    "\n",
    "\n",
    "##\n",
    "\n",
    "#KOMBINERER\n",
    "\n",
    "\n",
    "#i merge df og df1\n",
    "df = df.merge(df1, on='id', how='left')\n",
    "\n",
    "\n",
    "df.to_csv('ny_trafikkdata.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>heading</th>\n",
       "      <th>volume</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68511V2673383</td>\n",
       "      <td>Tromsøysundtunnelen T1</td>\n",
       "      <td>69.67012</td>\n",
       "      <td>19.018382</td>\n",
       "      <td>2018-01-01T22:00:00+01:00</td>\n",
       "      <td>2018-01-01T23:00:00+01:00</td>\n",
       "      <td>Tomasjord</td>\n",
       "      <td>141.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68511V2673383</td>\n",
       "      <td>Tromsøysundtunnelen T1</td>\n",
       "      <td>69.67012</td>\n",
       "      <td>19.018382</td>\n",
       "      <td>2018-01-01T22:00:00+01:00</td>\n",
       "      <td>2018-01-01T23:00:00+01:00</td>\n",
       "      <td>Tromsøya</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68511V2673383</td>\n",
       "      <td>Tromsøysundtunnelen T1</td>\n",
       "      <td>69.67012</td>\n",
       "      <td>19.018382</td>\n",
       "      <td>2018-01-01T23:00:00+01:00</td>\n",
       "      <td>2018-01-02T00:00:00+01:00</td>\n",
       "      <td>Tomasjord</td>\n",
       "      <td>68.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68511V2673383</td>\n",
       "      <td>Tromsøysundtunnelen T1</td>\n",
       "      <td>69.67012</td>\n",
       "      <td>19.018382</td>\n",
       "      <td>2018-01-01T23:00:00+01:00</td>\n",
       "      <td>2018-01-02T00:00:00+01:00</td>\n",
       "      <td>Tromsøya</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68511V2673383</td>\n",
       "      <td>Tromsøysundtunnelen T1</td>\n",
       "      <td>69.67012</td>\n",
       "      <td>19.018382</td>\n",
       "      <td>2018-01-02T00:00:00+01:00</td>\n",
       "      <td>2018-01-02T01:00:00+01:00</td>\n",
       "      <td>Tomasjord</td>\n",
       "      <td>33.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>68511V2673383</td>\n",
       "      <td>Tromsøysundtunnelen T1</td>\n",
       "      <td>69.67012</td>\n",
       "      <td>19.018382</td>\n",
       "      <td>2018-01-05T23:00:00+01:00</td>\n",
       "      <td>2018-01-06T00:00:00+01:00</td>\n",
       "      <td>Tromsøya</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>68511V2673383</td>\n",
       "      <td>Tromsøysundtunnelen T1</td>\n",
       "      <td>69.67012</td>\n",
       "      <td>19.018382</td>\n",
       "      <td>2018-01-06T00:00:00+01:00</td>\n",
       "      <td>2018-01-06T01:00:00+01:00</td>\n",
       "      <td>Tomasjord</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>68511V2673383</td>\n",
       "      <td>Tromsøysundtunnelen T1</td>\n",
       "      <td>69.67012</td>\n",
       "      <td>19.018382</td>\n",
       "      <td>2018-01-06T00:00:00+01:00</td>\n",
       "      <td>2018-01-06T01:00:00+01:00</td>\n",
       "      <td>Tromsøya</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>68511V2673383</td>\n",
       "      <td>Tromsøysundtunnelen T1</td>\n",
       "      <td>69.67012</td>\n",
       "      <td>19.018382</td>\n",
       "      <td>2018-01-06T01:00:00+01:00</td>\n",
       "      <td>2018-01-06T02:00:00+01:00</td>\n",
       "      <td>Tomasjord</td>\n",
       "      <td>24.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>68511V2673383</td>\n",
       "      <td>Tromsøysundtunnelen T1</td>\n",
       "      <td>69.67012</td>\n",
       "      <td>19.018382</td>\n",
       "      <td>2018-01-06T01:00:00+01:00</td>\n",
       "      <td>2018-01-06T02:00:00+01:00</td>\n",
       "      <td>Tromsøya</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                    name       lat        lon  \\\n",
       "1    68511V2673383  Tromsøysundtunnelen T1  69.67012  19.018382   \n",
       "2    68511V2673383  Tromsøysundtunnelen T1  69.67012  19.018382   \n",
       "3    68511V2673383  Tromsøysundtunnelen T1  69.67012  19.018382   \n",
       "4    68511V2673383  Tromsøysundtunnelen T1  69.67012  19.018382   \n",
       "5    68511V2673383  Tromsøysundtunnelen T1  69.67012  19.018382   \n",
       "..             ...                     ...       ...        ...   \n",
       "196  68511V2673383  Tromsøysundtunnelen T1  69.67012  19.018382   \n",
       "197  68511V2673383  Tromsøysundtunnelen T1  69.67012  19.018382   \n",
       "198  68511V2673383  Tromsøysundtunnelen T1  69.67012  19.018382   \n",
       "199  68511V2673383  Tromsøysundtunnelen T1  69.67012  19.018382   \n",
       "200  68511V2673383  Tromsøysundtunnelen T1  69.67012  19.018382   \n",
       "\n",
       "                          from                         to    heading  volume  \\\n",
       "1    2018-01-01T22:00:00+01:00  2018-01-01T23:00:00+01:00  Tomasjord   141.0   \n",
       "2    2018-01-01T22:00:00+01:00  2018-01-01T23:00:00+01:00   Tromsøya     0.0   \n",
       "3    2018-01-01T23:00:00+01:00  2018-01-02T00:00:00+01:00  Tomasjord    68.0   \n",
       "4    2018-01-01T23:00:00+01:00  2018-01-02T00:00:00+01:00   Tromsøya     0.0   \n",
       "5    2018-01-02T00:00:00+01:00  2018-01-02T01:00:00+01:00  Tomasjord    33.0   \n",
       "..                         ...                        ...        ...     ...   \n",
       "196  2018-01-05T23:00:00+01:00  2018-01-06T00:00:00+01:00   Tromsøya     0.0   \n",
       "197  2018-01-06T00:00:00+01:00  2018-01-06T01:00:00+01:00  Tomasjord    45.0   \n",
       "198  2018-01-06T00:00:00+01:00  2018-01-06T01:00:00+01:00   Tromsøya     0.0   \n",
       "199  2018-01-06T01:00:00+01:00  2018-01-06T02:00:00+01:00  Tomasjord    24.0   \n",
       "200  2018-01-06T01:00:00+01:00  2018-01-06T02:00:00+01:00   Tromsøya     0.0   \n",
       "\n",
       "     coverage  \n",
       "1      100.00  \n",
       "2      100.00  \n",
       "3      100.00  \n",
       "4      100.00  \n",
       "5      100.00  \n",
       "..        ...  \n",
       "196     99.38  \n",
       "197    100.00  \n",
       "198    100.00  \n",
       "199    100.00  \n",
       "200    100.00  \n",
       "\n",
       "[200 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at name Tromsøysundtunnellen T1\n",
    "df[df['name'] == 'Tromsøysundtunnelen T1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the start and end datetime objects\n",
    "start_datetime = datetime.datetime(2018, 1, 1, 23, 0, 0)\n",
    "end_datetime = datetime.datetime(2024, 6, 1, 23, 0, 0)\n",
    "\n",
    "# Define the time delta for each iteration\n",
    "time_delta = datetime.timedelta(hours=100)\n",
    "\n",
    "# Initialize the list to store the results\n",
    "all_rows = []\n",
    "\n",
    "# Loop through the time range and send the requests\n",
    "while start_datetime < end_datetime:\n",
    "    # Definerer GraphQL query med \"test\" for hver trafficRegistrationPointId og setter en new line for hver for å lese i request outputtet om det er rett\n",
    "    query = \"\"\"\n",
    "    {\n",
    "    \"\"\" + \"\\n\".join(\n",
    "        f\"\"\"\n",
    "    test_{id.replace(':', '_')}: trafficData(trafficRegistrationPointId: \"{id}\") {{\n",
    "        volume {{\n",
    "        byHour(\n",
    "            from: \"{start_datetime.isoformat()}+02:00\"\n",
    "            to: \"{(start_datetime + time_delta).isoformat()}+02:00\"\n",
    "        ) {{\n",
    "            edges {{\n",
    "            node {{\n",
    "                from\n",
    "                to\n",
    "                byDirection {{\n",
    "                heading\n",
    "                total {{\n",
    "                    volumeNumbers {{\n",
    "                        volume\n",
    "                    }}\n",
    "                    coverage {{\n",
    "                        percentage\n",
    "                        }}\n",
    "                }}\n",
    "                }}\n",
    "            }}\n",
    "            }}\n",
    "        }}\n",
    "        }}\n",
    "    }}\n",
    "        \"\"\"\n",
    "        for id in traffic_registration_point_ids\n",
    "    ) + \"}\"\n",
    "    \n",
    "    # setter inn link og overskrifter og definerer data for query\n",
    "    url = \"https://trafikkdata-api.atlas.vegvesen.no/\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"query\": query}\n",
    "\n",
    "    # Sender requesten og henter resultatet\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    result = response.json()\n",
    "\n",
    "    # henter resultatet fra data som er nestet\n",
    "    data = result['data']\n",
    "\n",
    "    # lager en liste of dictionaries, en for hver trafficregistrationpoint. jeg fjerner alias siden jeg ikke trenger det lengere. setter en \"if\" statement for å fjerne problem om nonetype og legger til 0 istedenfor der det er None\n",
    "    rows = [    \n",
    "        {        \n",
    "            'id': key.replace(\"test_\", \"\"),        \n",
    "            'from': item['node']['from'],\n",
    "            'to': item['node']['to'],\n",
    "            'heading': heading['heading'],\n",
    "            'volume': heading['total']['volumeNumbers']['volume'] if heading['total']['volumeNumbers'] is not None else 0,\n",
    "            'coverage': heading['total']['coverage']['percentage'] if heading['total']['coverage'] is not None else 0\n",
    "        }\n",
    "        for key, value in data.items()\n",
    "        for item in value['volume']['byHour']['edges']\n",
    "        for heading in item['node']['byDirection']\n",
    "    ]\n",
    "    \n",
    "    # Append the rows to the list of all rows\n",
    "    all_rows += rows\n",
    "    \n",
    "    # Increment the start datetime\n",
    "    start_datetime += time_delta\n",
    "\n",
    "# lager et dataframe fra listen av dictionaries\n",
    "df1 = pd.DataFrame.from_dict(all_rows)\n",
    "\n",
    "\n",
    "##\n",
    "\n",
    "#KOMBINERER\n",
    "\n",
    "\n",
    "#i merge df og df1\n",
    "df = df.merge(df1, on='id', how='left')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
